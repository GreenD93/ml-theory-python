{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorization\n",
    "\n",
    "Matrix factorization is one of model-based algorithm (or Latent Factor Model). Using the nature of the matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define\n",
    "\n",
    "- Basic concept of matrix factorization is `matrix completion`.\n",
    "- Fill the below image's `?` is main purpose of matrix completion.\n",
    "\n",
    "<img src=\"img/mf.png\" alt=\"MF\" style=\"width: 300px;\"/>\n",
    "\n",
    "- Matrix's row, column is factor of concept (e.g. Row: user, Column: Movie, Value: Rating)\n",
    "- And matrix factorization divide it two parts(P, Q). And they called `Latent Factor`.\n",
    "    - $ R \\approx P X Q^T = \\hat{R} $\n",
    "    - And Latent factor has their own dimension `k`.\n",
    "    - $ \\hat{r_{ij}} = p_i^T q_j = \\sum_{k=1}^k p_{ik}q_{kj} $\n",
    "    - The example of using latent factor\n",
    "        - **e.g.** When we have (User, Movie, Rating) matrix, we implicitically knows about every user has prefered genre. In this situation, user latent factor's dimension(k) maybe works like `prefer genre`. if k=3, each dimension value represent preference score of each genre. (romance = -1, action = 2, comedy = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Cost function & Train\n",
    "\n",
    "- Cost function of Matrix Factorization is below.\n",
    "\n",
    "$$ Cost = \\sum_{i,u \\in R_{train}} (r(i,u) - \\hat{r}(i,u) )^2 + \\lambda(b(i)^2 + b(u)^2 + ||p(i)||^2 ||q(u)||^2) $$\n",
    "\n",
    "- And we can use Gradient Descent.\n",
    "\n",
    "$$ \\grave{p_{ik}} = p_{ik} +\\alpha \\frac{dCost}{dp}$$\n",
    "\n",
    "\n",
    "$$ \\grave{q_{kj}} = q_{kj} +\\alpha \\frac{dCost}{dq}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 7X5 Matrix\n",
    "R = np.array([\n",
    "        [1, 0, 0, 1, 3],\n",
    "        [2, 0, 3, 1, 1],\n",
    "        [1, 2, 0, 5, 0],\n",
    "        [1, 0, 0, 4, 4],\n",
    "        [2, 1, 5, 4, 0],\n",
    "        [5, 1, 5, 4, 0],\n",
    "        [0, 0, 0, 1, 0],\n",
    "    ])\n",
    "\n",
    "# P, Q is (7 X k), (k X 5) matrix\n",
    "P = np.random.normal(size=(R.shape[0], 4))\n",
    "Q = np.random.normal(size=(R.shape[1], 4))\n",
    "\n",
    "# b_P, b_Q is (7 X 1), (5 X 1)\n",
    "b_P = np.ones(R.shape[0])\n",
    "b_Q = np.ones(R.shape[1])\n",
    "b = np.mean(R[np.where(R != 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.14544264,  0.76617751, -0.15163809, -1.14918166],\n",
       "       [-1.19423342,  1.62504796,  0.14128756,  0.07143081],\n",
       "       [-1.48406439, -1.2017517 ,  0.5767384 ,  0.49059089],\n",
       "       [-0.76688018, -1.12450154,  1.19667241, -2.22018095],\n",
       "       [ 0.63085357,  0.32312185,  0.81577999,  1.01556337],\n",
       "       [ 0.87686163,  0.60873574,  0.7956862 , -0.82178764],\n",
       "       [-0.41426823,  0.78840721, -0.67253972, -0.68151125]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.24450083, -0.56573807, -0.38928391,  0.49186013],\n",
       "       [-0.23816813, -0.73399454,  1.10309967,  0.75727339],\n",
       "       [ 0.68286032,  2.53800163,  0.0578524 ,  0.75766522],\n",
       "       [ 0.38358876, -0.82099596,  1.36663131,  0.09294516],\n",
       "       [ 0.35038026,  1.91152701,  0.09604263, -0.52097559]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.37118526,  2.71821442,  6.4381786 ,  4.08721513,  7.04095046],\n",
       "       [ 3.94368164,  3.89250802,  7.96208329,  2.99838392,  7.25515227],\n",
       "       [ 5.65042787,  6.83415649,  0.93252199,  5.84205877,  1.57354699],\n",
       "       [ 3.85672146,  5.23769848, -0.39967323,  6.64900861,  3.44428597],\n",
       "       [ 4.43580764,  5.87243597,  6.65842961,  5.77687787,  4.97886979],\n",
       "       [ 3.3181783 ,  4.19066317,  6.15804784,  5.43852227,  6.56630999],\n",
       "       [ 4.17276672,  2.85291931,  5.75373514,  2.80226431,  6.24327761]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_hat = b + b_P[:, np.newaxis] + b_Q[np.newaxis:, ] + P.dot(Q.T)\n",
    "R_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.37118526, -2.71821442, -6.4381786 , -3.08721513, -4.04095046],\n",
       "       [-1.94368164, -3.89250802, -4.96208329, -1.99838392, -6.25515227],\n",
       "       [-4.65042787, -4.83415649, -0.93252199, -0.84205877, -1.57354699],\n",
       "       [-2.85672146, -5.23769848,  0.39967323, -2.64900861,  0.55571403],\n",
       "       [-2.43580764, -4.87243597, -1.65842961, -1.77687787, -4.97886979],\n",
       "       [ 1.6818217 , -3.19066317, -1.15804784, -1.43852227, -6.56630999],\n",
       "       [-4.17276672, -2.85291931, -5.75373514, -1.80226431, -6.24327761]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = R - R_hat\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 5)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.62387553e+00, -1.74271007e+01, -7.20668767e+00,\n",
       "        -7.43359379e+00],\n",
       "       [-6.13857955e+00, -1.73282606e+01, -7.01477647e+00,\n",
       "        -4.51883788e+00],\n",
       "       [-7.06815257e-01,  2.94123809e-01, -4.30134139e+00,\n",
       "        -5.42257245e+00],\n",
       "       [ 6.30545732e-01,  8.58755567e+00, -7.01267918e+00,\n",
       "        -7.82456550e+00],\n",
       "       [-1.17169430e+00, -6.99003924e+00, -6.61324659e+00,\n",
       "        -2.70009643e+00],\n",
       "       [-2.41772213e+00, -1.23105907e+01, -6.04221049e+00,\n",
       "        -9.99994852e-04],\n",
       "       [-5.52239582e+00, -1.98144038e+01, -5.59072211e+00,\n",
       "        -6.16869025e+00]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff.dot(Q) + P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 6]),\n",
       " array([0, 3, 4, 0, 2, 3, 4, 0, 1, 3, 0, 3, 4, 0, 1, 2, 3, 0, 1, 2, 3, 3]))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_area = R.nonzero()\n",
    "train_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "0 3\n",
      "0 4\n",
      "1 0\n",
      "1 2\n",
      "1 3\n",
      "1 4\n",
      "2 0\n",
      "2 1\n",
      "2 3\n",
      "3 0\n",
      "3 3\n",
      "3 4\n",
      "4 0\n",
      "4 1\n",
      "4 2\n",
      "4 3\n",
      "5 0\n",
      "5 1\n",
      "5 2\n",
      "5 3\n",
      "6 3\n"
     ]
    }
   ],
   "source": [
    "for i, j in zip(train_area[0], train_area[1]):\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Alternating Least Squares\n",
    "----\n",
    "\n",
    "ALS is specific optimizer for Matrix Factorization.\n",
    "\n",
    "- Learn `User Latent Factor` and `Item Latent Factor` alternately.\n",
    "- Because training both factors sometimes very inefficient.\n",
    "- There are two step in ALS.\n",
    "    - Set `Item Latent Factor` as constant for learn to `User Latent Factor`\n",
    "- The original cost function of matrix factorization is below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ min_{q,p} \\sum_{u,i}(r_{ui}-q_i^Tp_u)^2 + \\lambda(||q_i||^2 + ||p_u||^2) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- And there is ALS's cost function.\n",
    "\n",
    "$$ min_{x,y} \\sum c_{ui}(p_{ui}-x_i^Ty_u)^2 + \\lambda(||x_i||^2 + ||y_u||^2) $$\n",
    "\n",
    "- We can see two difference like this\n",
    "    - $ p_{ui} $ is preference score(binary score) in Explicit feedback\n",
    "        - p is 1 if $ r_{ui} > 0 $\n",
    "        - p is 0 if $ r_{ui} = 0 $\n",
    "    - $ c_{ui} $ is confidence for $ p_{ui} $.\n",
    "        - $ c_{ui} = 1 + \\alpha* r_{ui} $\n",
    "        - If there are no score(p score), sparse matrix is very inefficient. (Almost implicit situation has sparse matrix problem)\n",
    "        - c score can solve this problem. If we use this, many zero values turn to non-zero (almost zero) value. So the model's performance is better than before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Learning Step\n",
    "    - 1) Fix Y's latent factor - $ \\frac{dL(x_i)}{dx_i} = -2\\sum c_{ui}(p_{ui}-x_i^Ty_u)*y_u + 2\\lambda x_i $\n",
    "        - Find $ \\frac{dL(x_i)}{dx_i} $ is 0\n",
    "        - $ \\sum_i c_{ui}(x_i^Ty_u)*y_u +\\lambda x_i = \\sum_i c_{ui}(p_{ui})*y_u $\n",
    "        - $ \\sum_i c_{ui}(y_u^Tx_i)*y_u +\\lambda x_i = \\sum_i c_{ui}(p_{ui})*y_u $\n",
    "        - $ (\\sum_i c_{ui}*y_u*y_u^T +\\lambda I )x_i = \\sum_i c_{ui}(p_{ui})*y_u $\n",
    "        - $ x_i = (Y^T c^i Y + \\lambda I)^{-1} Y^T c^i p(u) $\n",
    "    - 2) Fix X's latent factor\n",
    "    - iter loop~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## SVD (Singular Value Decomposition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "#### references\n",
    "- https://yamalab.tistory.com/92\n",
    "- https://yeomko.tistory.com/4\n",
    "- https://datascienceschool.net/view-notebook/fcd3550f11ac4537acec8d18136f2066/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
