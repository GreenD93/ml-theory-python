{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1. linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# note from : https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/01-basics/pytorch_basics/main.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "x_train = np.array([[3.3], [4.4], [5.5], [6.71], [6.93], [4.168], \n",
    "                    [9.779], [6.182], [7.59], [2.167], [7.042], \n",
    "                    [10.791], [5.313], [7.997], [3.1]], dtype=np.float32)\n",
    "\n",
    "y_train = np.array([[1.7], [2.76], [2.09], [3.19], [1.694], [1.573], \n",
    "                    [3.366], [2.596], [2.53], [1.221], [2.827], \n",
    "                    [3.465], [1.65], [2.904], [1.3]], dtype=np.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# define model\n",
    "model = nn.Linear(1, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# define loss function & optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)  "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Epoch [5/10], Loss: 0.1689\nEpoch [10/10], Loss: 0.1689\nEpoch [15/10], Loss: 0.1689\nEpoch [20/10], Loss: 0.1689\nEpoch [25/10], Loss: 0.1689\nEpoch [30/10], Loss: 0.1689\nEpoch [35/10], Loss: 0.1689\nEpoch [40/10], Loss: 0.1689\nEpoch [45/10], Loss: 0.1689\nEpoch [50/10], Loss: 0.1689\nEpoch [55/10], Loss: 0.1689\nEpoch [60/10], Loss: 0.1689\nEpoch [65/10], Loss: 0.1689\nEpoch [70/10], Loss: 0.1689\nEpoch [75/10], Loss: 0.1689\nEpoch [80/10], Loss: 0.1689\nEpoch [85/10], Loss: 0.1689\nEpoch [90/10], Loss: 0.1689\nEpoch [95/10], Loss: 0.1689\nEpoch [100/10], Loss: 0.1689\nEpoch [105/10], Loss: 0.1689\nEpoch [110/10], Loss: 0.1689\nEpoch [115/10], Loss: 0.1689\nEpoch [120/10], Loss: 0.1689\nEpoch [125/10], Loss: 0.1689\nEpoch [130/10], Loss: 0.1689\nEpoch [135/10], Loss: 0.1689\nEpoch [140/10], Loss: 0.1689\nEpoch [145/10], Loss: 0.1689\nEpoch [150/10], Loss: 0.1689\nEpoch [155/10], Loss: 0.1689\nEpoch [160/10], Loss: 0.1689\nEpoch [165/10], Loss: 0.1689\nEpoch [170/10], Loss: 0.1689\nEpoch [175/10], Loss: 0.1689\nEpoch [180/10], Loss: 0.1689\nEpoch [185/10], Loss: 0.1689\nEpoch [190/10], Loss: 0.1689\nEpoch [195/10], Loss: 0.1689\nEpoch [200/10], Loss: 0.1689\nEpoch [205/10], Loss: 0.1689\nEpoch [210/10], Loss: 0.1689\nEpoch [215/10], Loss: 0.1689\nEpoch [220/10], Loss: 0.1689\nEpoch [225/10], Loss: 0.1689\nEpoch [230/10], Loss: 0.1689\nEpoch [235/10], Loss: 0.1689\nEpoch [240/10], Loss: 0.1689\nEpoch [245/10], Loss: 0.1689\nEpoch [250/10], Loss: 0.1689\nEpoch [255/10], Loss: 0.1689\nEpoch [260/10], Loss: 0.1689\nEpoch [265/10], Loss: 0.1689\nEpoch [270/10], Loss: 0.1689\nEpoch [275/10], Loss: 0.1689\nEpoch [280/10], Loss: 0.1689\nEpoch [285/10], Loss: 0.1689\nEpoch [290/10], Loss: 0.1689\nEpoch [295/10], Loss: 0.1689\nEpoch [300/10], Loss: 0.1689\nEpoch [305/10], Loss: 0.1689\nEpoch [310/10], Loss: 0.1689\nEpoch [315/10], Loss: 0.1689\nEpoch [320/10], Loss: 0.1689\nEpoch [325/10], Loss: 0.1689\nEpoch [330/10], Loss: 0.1689\nEpoch [335/10], Loss: 0.1689\nEpoch [340/10], Loss: 0.1689\nEpoch [345/10], Loss: 0.1689\nEpoch [350/10], Loss: 0.1689\nEpoch [355/10], Loss: 0.1689\nEpoch [360/10], Loss: 0.1689\nEpoch [365/10], Loss: 0.1689\nEpoch [370/10], Loss: 0.1689\nEpoch [375/10], Loss: 0.1689\nEpoch [380/10], Loss: 0.1689\nEpoch [385/10], Loss: 0.1689\nEpoch [390/10], Loss: 0.1689\nEpoch [395/10], Loss: 0.1689\nEpoch [400/10], Loss: 0.1689\nEpoch [405/10], Loss: 0.1689\nEpoch [410/10], Loss: 0.1689\nEpoch [415/10], Loss: 0.1689\nEpoch [420/10], Loss: 0.1689\nEpoch [425/10], Loss: 0.1689\nEpoch [430/10], Loss: 0.1689\nEpoch [435/10], Loss: 0.1689\nEpoch [440/10], Loss: 0.1689\nEpoch [445/10], Loss: 0.1689\nEpoch [450/10], Loss: 0.1689\nEpoch [455/10], Loss: 0.1689\nEpoch [460/10], Loss: 0.1689\nEpoch [465/10], Loss: 0.1689\nEpoch [470/10], Loss: 0.1689\nEpoch [475/10], Loss: 0.1689\nEpoch [480/10], Loss: 0.1689\nEpoch [485/10], Loss: 0.1689\nEpoch [490/10], Loss: 0.1689\nEpoch [495/10], Loss: 0.1689\nEpoch [500/10], Loss: 0.1689\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(500):\n",
    "    # Convert numpy arrays to torch tensors\n",
    "    inputs = torch.from_numpy(x_train)\n",
    "    targets = torch.from_numpy(y_train)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    \n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 5 == 0:\n",
    "        print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, 10, loss.item()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the graph\n",
    "predicted = model(torch.from_numpy(x_train)).detach().numpy()\n",
    "plt.plot(x_train, y_train, 'ro', label='Original data')\n",
    "plt.plot(x_train, predicted, label='Fitted line')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Logistic regression with dataset\n",
    "### 1) prepare dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "class LibsvmTransformer:\n",
    "    def __init__(self, train_path, valid_path, batch_size, input_dim):\n",
    "        self._train_path = train_path\n",
    "        self._valid_path = valid_path\n",
    "        self._batch_size = batch_size\n",
    "        self._input_dim = input_dim\n",
    "        self._init_stream()\n",
    "        \n",
    "    def _init_stream(self):\n",
    "        self._train_streamer = self.stream_docs(path=self._train_path)\n",
    "        \n",
    "    def stream_docs(self, path):\n",
    "        \"\"\"\n",
    "        Lazy function (generator) to read a file piece by piece.\n",
    "        Transform libsvm data format to numpy array.\n",
    "        \"\"\"\n",
    "        with open(path, 'r', encoding='utf-8') as txt:\n",
    "            for line in txt:\n",
    "                if not line:\n",
    "                    break\n",
    "                y = int(line[0])\n",
    "                x = np.zeros(self._input_dim)\n",
    "                for tup in line[2:].split(\" \"):\n",
    "                    x[int(tup.split(\":\")[0])] = int(tup.split(\":\")[1])\n",
    "                yield x, y\n",
    "                \n",
    "    def get_minibatch(self):\n",
    "        \"\"\"\n",
    "        Get mini-batch from dataset generator  \n",
    "        \"\"\"\n",
    "        X = []\n",
    "        Y = []\n",
    "        try:\n",
    "            for _ in range(self._batch_size):\n",
    "                x_i, y_i = next(self._train_streamer)\n",
    "                X.append(x_i)\n",
    "                Y.append(y_i)\n",
    "        except StopIteration:\n",
    "            return None, None\n",
    "        return np.array(X, dtype=np.float32), np.array(Y)\n",
    "\n",
    "data_transformer = LibsvmTransformer(train_path='../../dataset/train.txt',\n",
    "                                     valid_path='../../dataset/test.txt',\n",
    "                                     input_dim=37,\n",
    "                                     batch_size=64)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "# define model\n",
    "model = nn.Linear(37, 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "# define loss function & optimizer\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([[ 0.1416, -0.1956],\n        [ 0.2136,  0.1318],\n        [ 0.2254,  0.0574],\n        [-0.0554,  0.1409],\n        [ 0.3044,  0.0236],\n        [ 0.2772, -0.1779],\n        [ 0.3940, -0.0851],\n        [ 0.2525, -0.0462],\n        [ 0.0269,  0.0236],\n        [ 0.2772, -0.1779],\n        [ 0.1416, -0.1956],\n        [ 0.2136,  0.1318],\n        [ 0.5570, -0.0475],\n        [ 0.2136,  0.1318],\n        [ 0.1541,  0.2584],\n        [ 0.1416, -0.1956],\n        [ 0.2524,  0.0218],\n        [-0.0538, -0.1635],\n        [ 0.5210, -0.0789],\n        [ 0.1416, -0.1956],\n        [ 0.1373,  0.3129],\n        [ 0.4474, -0.0936],\n        [-0.5255,  0.3582],\n        [ 0.1876, -0.0692],\n        [ 0.4589,  0.2812],\n        [ 0.5644, -0.1825],\n        [ 0.1876, -0.0692],\n        [ 0.3119, -0.1047],\n        [ 0.2585, -0.2220],\n        [ 0.0228, -0.0673],\n        [-0.1129, -0.0851],\n        [ 0.1416, -0.1956],\n        [-0.1129, -0.0851],\n        [ 0.5210, -0.0789],\n        [ 0.1807, -0.1640],\n        [ 0.1416, -0.1956],\n        [ 0.1416, -0.1956],\n        [ 0.1876, -0.0692],\n        [ 0.2326, -0.0942],\n        [-0.0622, -0.3793],\n        [ 0.3016,  0.2017],\n        [ 0.2583, -0.1028],\n        [ 0.0228, -0.0673],\n        [-0.2591, -0.0427],\n        [ 0.1416, -0.1956],\n        [-0.1497,  0.0859],\n        [ 0.0222, -0.4169],\n        [ 0.1416, -0.1956],\n        [ 0.4400,  0.0414],\n        [ 0.5570, -0.0475],\n        [ 0.1416, -0.1956],\n        [ 0.1416, -0.1956],\n        [ 0.1416, -0.1956],\n        [ 0.5210, -0.0789],\n        [ 0.1416, -0.1956],\n        [ 0.1416, -0.1956],\n        [-0.0199, -0.2048],\n        [ 0.1990,  0.0304],\n        [-0.1295, -0.2938],\n        [-0.1129, -0.0851],\n        [ 0.2688, -0.1082],\n        [ 0.4694, -0.1034],\n        [-0.0199, -0.2048],\n        [ 0.1416, -0.1956]], grad_fn=<AddmmBackward>)\nEpoch [5/10], Loss: 0.7271\n",
      "tensor([[ 0.2536,  0.0680],\n        [-0.0986, -0.0994],\n        [ 0.2013, -0.0829],\n        [ 0.3874, -0.1553],\n        [ 0.0332,  0.1926],\n        [-0.0633,  0.2614],\n        [-0.0057, -0.2190],\n        [ 0.1964, -0.2432],\n        [ 0.1569, -0.2110],\n        [-0.0244,  0.1276],\n        [ 0.1569, -0.2110],\n        [-0.0498, -0.3916],\n        [ 0.1451,  0.1959],\n        [ 0.7343, -0.1917],\n        [ 0.0372, -0.2977],\n        [ 0.4582,  0.2819],\n        [ 0.2012, -0.0140],\n        [ 0.3945, -0.0855],\n        [ 0.2580, -0.1794],\n        [ 0.3095,  0.0184],\n        [ 0.4414,  0.1034],\n        [ 0.1771, -0.2035],\n        [ 0.1569, -0.2110],\n        [ 0.1569, -0.2110],\n        [ 0.2862, -0.1869],\n        [ 0.2862, -0.1869],\n        [ 0.1184, -0.1727],\n        [ 0.4270, -0.2334],\n        [ 0.1569, -0.2110],\n        [ 0.1569, -0.2110],\n        [ 0.4187,  0.3141],\n        [ 0.2675,  0.1597],\n        [ 0.2971,  0.2062],\n        [ 0.1569, -0.2110],\n        [ 0.2477, -0.1486],\n        [ 0.3512, -0.1846],\n        [-0.1968,  0.1062],\n        [ 0.2332,  0.0547],\n        [ 0.2862, -0.1869],\n        [-0.0436, -0.1181],\n        [ 0.1964, -0.2432],\n        [ 0.2862, -0.1869],\n        [-0.3206,  0.0153],\n        [ 0.4575,  0.1362],\n        [ 0.0219, -0.0023],\n        [ 0.2274, -0.2347],\n        [ 0.4582,  0.2819],\n        [ 0.1060,  0.0151],\n        [ 0.3945, -0.0855],\n        [ 0.3168, -0.1165],\n        [-0.1344,  0.1927],\n        [ 0.1569, -0.2110],\n        [-0.0830, -0.3756],\n        [ 0.1569, -0.2110],\n        [-0.1756,  0.0275],\n        [ 0.1833,  0.1717],\n        [ 0.3080, -0.2533],\n        [ 0.0977,  0.1537],\n        [ 0.5581, -0.0486],\n        [ 0.1655,  0.0024],\n        [-0.0057, -0.2190],\n        [ 0.3854, -0.0967],\n        [ 0.1569, -0.2110],\n        [-0.0498, -0.3916]], grad_fn=<AddmmBackward>)\nEpoch [10/10], Loss: 0.7022\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-ee63c74724e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Convert numpy arrays to torch tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_transformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_minibatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected np.ndarray (got NoneType)"
     ],
     "ename": "TypeError",
     "evalue": "expected np.ndarray (got NoneType)",
     "output_type": "error"
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(500):\n",
    "    # Convert numpy arrays to torch tensors\n",
    "    x_train, y_train = data_transformer.get_minibatch()\n",
    "    inputs = torch.from_numpy(x_train)\n",
    "    targets = torch.from_numpy(y_train)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    \n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 5 == 0:\n",
    "        print(outputs)\n",
    "        print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, 10, loss.item()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"python with open yield reset\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}